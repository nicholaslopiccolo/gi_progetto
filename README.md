# gi_progetto
Progetto di gestione dell'informazione, sviluppato in cooperazione con Daniele Bianchini.

# Web crawlers construction python:
- Scrapy framework 
- BeautifulSoup

# Installazione ed esecuzione

```shell
pip3 install -r requirements.txt

python
>>import nltk
>>nltk.download('book')
>>nltk.download('stopwords')
>>nltk.download('omw-1.4')
>>exit()

cd src
python3 main.py
```
# Esecuzione Crawling
Al primo avvio, selezionare la voce del menu webcrawling, dare un minimo di 300 come limite e lasciare calcolare ( almeno 10 min )

# Esecuzione benchmark

cancella cartella Docs, rinomina cartella Docs_benchmark in Docs
esegui main.py